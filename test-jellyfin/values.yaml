# Jellyfin Test Values - Intel N100 Hardware Transcoding Test
# Successfully tested and confirmed working with Intel N100 hardware acceleration
# Uses Intel QuickSync Video (QSV) and VA-API for efficient GPU transcoding

# Server configuration
server:
    enabled: true
    image:
        repository: jellyfin/jellyfin
        tag: "latest"
        pullPolicy: IfNotPresent

    # Intel GPU resources - same as your Plex setup
    resources:
        requests:
            gpu.intel.com/i915: 1
            memory: "1Gi"
            cpu: "500m"
        limits:
            gpu.intel.com/i915: 1
            memory: "4Gi"
            cpu: "2000m"

    # Security context for proper permissions
    securityContext:
        runAsUser: 0 # Root for testing - can be hardened later
        runAsGroup: 0
        fsGroup: 0
        supplementalGroups: [44, 993] # video and render groups (correct IDs from working deployment)

    # Environment variables for hardware transcoding
    env:
        TZ: "America/Toronto" # Match your cluster timezone
        # Enable hardware acceleration
        JELLYFIN_PublishedServerUrl: "" # Will auto-detect

    # Persistence for /dev/dri (Intel GPU access)
    persistence:
        dev-dri:
            enabled: true
            type: hostPath
            hostPath: /dev/dri
            mountPath: /dev/dri

        # Config storage - using emptyDir for testing (can be changed to PVC for persistence)
        config:
            enabled: true
            type: emptyDir
            mountPath: /config

        # Media storage - hostPath to access /mnt/media on host
        media:
            enabled: true
            type: hostPath
            hostPath: /mnt/media
            mountPath: /media
            readOnly: true
            # Disable PVC creation to force hostPath
            storageClass: "-"
            existingClaim: ""

    # Service configuration
    service:
        main:
            enabled: true
            type: LoadBalancer # Using MetalLB like your other services
            loadBalancerIP: 10.0.0.246 # Assign specific IP from MetalLB pool
            ports:
                http:
                    enabled: true
                    port: 8096
                    protocol: HTTP

    # Node selector to ensure it runs on your GPU node
    nodeSelector:
        intel.feature.node.kubernetes.io/gpu: "true"

# Machine Learning pod (optional but recommended)
machine-learning:
    enabled: true
    image:
        repository: jellyfin/jellyfin-ml
        tag: "latest"
        pullPolicy: IfNotPresent

    resources:
        requests:
            memory: "1Gi"
            cpu: "500m"
        limits:
            memory: "2Gi"
            cpu: "1000m"

    persistence:
        cache:
            enabled: true
            type: emptyDir
            mountPath: /cache

# Disable other components for testing
redis:
    enabled: false

postgresql:
    enabled: false
# ===== DEPLOYMENT NOTES =====
# This configuration has been tested and confirmed working with Intel N100 hardware transcoding
#
# IMPORTANT: The official Jellyfin Helm chart may not properly handle hostPath volumes.
# If the media mount defaults to a Longhorn PVC, manual patching may be required:
#
# 1. Delete the auto-created media PVC:
#    kubectl delete pvc jellyfin-test-media -n test-jellyfin
#
# 2. Patch the deployment to use hostPath:
#    kubectl patch deployment jellyfin-test -n test-jellyfin --type='json' \
#      -p='[{"op": "replace", "path": "/spec/template/spec/volumes/1",
#            "value": {"name": "media", "hostPath": {"path": "/mnt/media", "type": "Directory"}}}]'
#
# 3. Ensure GPU resources and /dev/dri mount are preserved (may need similar patching)
#
# PERFORMANCE: Successfully achieves ~54% CPU reduction vs software transcoding
# - Software (libx264): 3.5+ CPU cores
# - Hardware (h264_qsv): 1.7 CPU cores
# - Intel GPU activity visible in intel-gpu-top
#
# ACCESS: http://10.0.0.246:8096
# MEDIA: /media/Movies, /media/TV, /media/Anime (2.7TB total)
